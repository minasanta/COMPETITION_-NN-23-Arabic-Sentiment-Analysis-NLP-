{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "922ebdaa",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6ee993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#import Stemmer\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re, string, emoji\n",
    "import qalsadi.lemmatizer \n",
    "import pyarabic.araby as ar\n",
    "import langid # => English Text\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from emoji import demojize\n",
    "from nltk.stem import ISRIStemmer\n",
    "from gensim.models import FastText\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from langid.langid import LanguageIdentifier, model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Embedding, Dense, Dropout, LSTM, BatchNormalization#, SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d6210",
   "metadata": {},
   "source": [
    "### Reading/Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05fba305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_description</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شركه زباله و سواقين بتبرشم و مفيش حتي رقم للشك...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>خدمة الدفع عن طريق الكي نت توقفت عندي اصبح فقط...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تطبيق غبي و جاري حذفه ، عاملين اكواد خصم و لما...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>فعلا تطبيق ممتاز بس لو فى امكانية يتيح لمستخدم...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سيء جدا ، اسعار رسوم التوصيل لا تمت للواقع ب ص...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32031</th>\n",
       "      <td>التطبيق اصبح سيء للغايه نقوم بطلب لا يتم وصول ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32032</th>\n",
       "      <td>y love you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32033</th>\n",
       "      <td>الباقه بتخلص وبشحن مرتين باقه اضافيه ١٠٠ جنيه</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32034</th>\n",
       "      <td>تطبيق فاشل وصلني الطلب ناقص ومش ينفع اعمل حاجة...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32035</th>\n",
       "      <td>ليش ما يفتح معي</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32036 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      review_description  rating\n",
       "0      شركه زباله و سواقين بتبرشم و مفيش حتي رقم للشك...      -1\n",
       "1      خدمة الدفع عن طريق الكي نت توقفت عندي اصبح فقط...       1\n",
       "2      تطبيق غبي و جاري حذفه ، عاملين اكواد خصم و لما...      -1\n",
       "3      فعلا تطبيق ممتاز بس لو فى امكانية يتيح لمستخدم...       1\n",
       "4      سيء جدا ، اسعار رسوم التوصيل لا تمت للواقع ب ص...      -1\n",
       "...                                                  ...     ...\n",
       "32031  التطبيق اصبح سيء للغايه نقوم بطلب لا يتم وصول ...      -1\n",
       "32032                                         y love you       1\n",
       "32033      الباقه بتخلص وبشحن مرتين باقه اضافيه ١٠٠ جنيه      -1\n",
       "32034  تطبيق فاشل وصلني الطلب ناقص ومش ينفع اعمل حاجة...      -1\n",
       "32035                                    ليش ما يفتح معي       1\n",
       "\n",
       "[32036 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"train.xlsx\" # Path on Kaggle: /kaggle/input/arabic-sentiment-analysis-nlp/train.xlsx\n",
    "df_train = pd.read_excel(file_path)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7055ec3",
   "metadata": {},
   "source": [
    "### Checking/Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a5ddd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "review_description    0\n",
       "rating                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for NULL/Missing Values\n",
    "missing_values = df_train.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72918436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of values in the 'rating' column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rating\n",
       " 1    19189\n",
       "-1    11340\n",
       " 0     1507\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Imbalances/Bias in Data\n",
    "rating_distribution = df_train['rating'].value_counts()\n",
    "print(\"Distribution of values in the 'rating' column:\")\n",
    "rating_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb8ab5",
   "metadata": {},
   "source": [
    "##### Imbalanced data => We can manipulate class weights later.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f96f9282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with English text: 780 rows × 1 columns\n"
     ]
    }
   ],
   "source": [
    "# Arabic Only?\n",
    "#english_rows = df_train[df_train['review_description'].apply(lambda x: langid.classify(x)[0] == 'en')]\n",
    "#english_rows[['review_description']]\n",
    "print(\"Rows with English text: 780 rows × 1 columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2030533",
   "metadata": {},
   "source": [
    "##### Data is Mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549fee2",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1c3e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_stop_words = [\n",
    "    \"و\", \"في\", \"من\", \"على\", \"إلى\", \"لا\", \"أو\", \"هو\", \"هي\", \"يكون\",\n",
    "    \"أنا\", \"أنت\", \"هو\", \"هي\", \"نحن\", \"أنتم\", \"هم\",\n",
    "    \"عن\", \"مع\", \"كما\", \"مثل\", \"بين\", \"إذا\", \"حتى\", \"منذ\",\n",
    "    \"و\", \"أو\", \"لكن\", \"إذا\", \"إن\",\n",
    "    \"اليوم\", \"غداً\", \"الآن\", \"ثم\", \"بعد\",\n",
    "    \"كان\", \"يكون\", \"أصبح\", \"صار\", \"ليس\", \"لم\",\n",
    "    \"هذا\", \"هذه\", \"ذلك\", \"تلك\", \n",
    "    \"كل\", \"على\", \"فيه\", \"منه\", \"عنه\", \"له\", \"به\", \"إليه\", \"لها\", \"فيها\",\n",
    "    \"بها\", \"منها\", \"عنها\", \"إليها\", \"الذي\", \"التي\", \"اللذين\", \"اللذان\", \"اللتان\",\n",
    "    \"اللتين\", \"هؤلاء\", \"ذلك\", \"هذه\", \"هذا\", \"تلك\", \"تحت\", \"فوق\", \"معه\", \"لديه\",\n",
    "    \"عليه\", \"عليها\", \"أي\", \"هل\", \"إذا\", \"ماذا\", \"هناك\", \"هنالك\", \"إلى\",\n",
    "    \"يناير\", \"فبراير\", \"مارس\", \"إبريل\", \"مايو\", \"يونيو\", \"يوليو\", \"أغسطس\", \"سبتمبر\", \"أكتوبر\", \"نوفمبر\", \"ديسمبر\",\n",
    "    \"الأحد\", \"الاثنين\", \"الثلاثاء\", \"الأربعاء\", \"الخميس\", \"الجمعة\", \"السبت\"\n",
    "]\n",
    "\n",
    "english_stop_words = set(stopwords.words('english'))\n",
    "\n",
    "negation_words = [\n",
    "    \"لا\", \"لما\", \"لن\", \"ليس\", \"ما\", \"لم\", \"لات\", \"غير\", \"لنعم\", \"ليست\", \"لست\", \"مطلقاً\",\n",
    "    \"no\", \"not\", \"never\", \"none\", \"nobody\", \"nothing\", \"nowhere\", \"neither\", \"nor\",\n",
    "    \"cannot\", \"can't\", \"won't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"hasn't\", \"haven't\", \"doesn't\", \"don't\",\n",
    "    \"didn't\", \"shouldn't\", \"wouldn't\", \"couldn't\", \"mustn't\", \"mightn't\", \"ain't\"\n",
    "]\n",
    "\n",
    "def handle_negations(tokens):\n",
    "    negation_flag = False\n",
    "    result_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.lower() in negation_words:\n",
    "            negation_flag = True\n",
    "        elif negation_flag and token.isalpha():\n",
    "            result_tokens.append(f\"NOT_{token}\")\n",
    "            negation_flag = False\n",
    "        else:\n",
    "            result_tokens.append(token)\n",
    "\n",
    "    return result_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e7b712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing_pipeline(text, stemmer, lemmatizer, tokenizer, stop_words):\n",
    "    # Unicode Normalization\n",
    "    text = unicodedata.normalize('NFD', text.lower())\n",
    "    \n",
    "    # Convert emojis to text\n",
    "    text = demojize(text)\n",
    "    # Add space between emojis\n",
    "    text = re.sub(r\"(:[a-zA-Z0-9_]+:)\", r\" \\1 \", text)\n",
    "    # Handling cases like \"♡♡♡\"\n",
    "    text = re.sub(r\"[♥☆★♡🖒]+\", \" good_review \", text)\n",
    "    \n",
    "    # Handling extra whitespaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # Handling numeric ratings like \"100/100\" or \"10/10\"\n",
    "    match = re.search(r\"(\\d+)\\s*(?:من|\\s|\\/)\\s*(\\d+)\", text)\n",
    "    if match:\n",
    "        left_number = float(match.group(1))\n",
    "        right_number = float(match.group(2))\n",
    "        if left_number <= 0.4 * right_number:\n",
    "            text = \"bad_rating\"\n",
    "        else:\n",
    "            text =\"good_rating\"\n",
    "            \n",
    "    text = re.sub(r\"\\b(?:\\d{1,3}(?:\\d{3})*(?:\\.\\d+)?%?|100٪)\\b\", \"good_review\", text)\n",
    "            \n",
    "    # Removing Digits\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "        \n",
    "    # Removing Punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)) # !\"#$%&'()*+,./:;<=>?@[\\]^`{|}~\n",
    "    \n",
    "    # src = https://github.com/linuxscout/pyarabic/blob/master/doc/features.md\n",
    "    text = ar.strip_tashkeel(text)\n",
    "    text = ar.normalize_hamza(text, method=\"tasheel\")\n",
    "    text = ar.strip_tatweel(text) # العـــــربية -> العربية\n",
    "    text = text.replace(\"اا\", \"ا\")\n",
    "    \n",
    "    # Language Identification\n",
    "    lang, confidence = langid.classify(text)\n",
    "    \n",
    "    if lang == 'ar':\n",
    "        # Arabic text processing\n",
    "        stemmed_tokens = stemmer.lemmatize_text(text)\n",
    "        # Stop-Words-Removal\n",
    "        filtered_tokens = [token for token in stemmed_tokens if token.lower() not in stop_words]\n",
    "    else:\n",
    "        # Tokenization\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        \n",
    "        # Stop-Words-Removal\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "        \n",
    "        # English text processing\n",
    "        stemmed_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    \n",
    "    # Handling negations\n",
    "    final_tokens = handle_negations(stemmed_tokens)\n",
    "    \n",
    "    text = \" \".join(final_tokens)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df5f141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializating/Preparing Stemmer, Lemmatizer, Tokenizer & Stop-Words\n",
    "#stemmer = ISRIStemmer()\n",
    "#stemmer = FarasaStemmer()\n",
    "#stemmer = Stemmer.Stemmer(\"arabic\")\n",
    "stemmer = qalsadi.lemmatizer.Lemmatizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "stop_words = set(english_stop_words).union(set(arabic_stop_words)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae2e0fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_description</th>\n",
       "      <th>rating</th>\n",
       "      <th>final_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شركه زباله و سواقين بتبرشم و مفيش حتي رقم للشك...</td>\n",
       "      <td>-1</td>\n",
       "      <td>شرك زبال سواق بتبرشم مفيش حت رقم للشكاوي سواق ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>خدمة الدفع عن طريق الكي نت توقفت عندي اصبح فقط...</td>\n",
       "      <td>1</td>\n",
       "      <td>خدم دفع طريق كي نات توقف عند صبح فقط دفع نقد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تطبيق غبي و جاري حذفه ، عاملين اكواد خصم و لما...</td>\n",
       "      <td>-1</td>\n",
       "      <td>تطبيق غب جار حذف عامل اكواد خصم NOT_استخدم اكت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>فعلا تطبيق ممتاز بس لو فى امكانية يتيح لمستخدم...</td>\n",
       "      <td>1</td>\n",
       "      <td>علا تطبيق ممتاز بس لو فى امكانية أتاح مستخدم ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سيء جدا ، اسعار رسوم التوصيل لا تمت للواقع ب ص...</td>\n",
       "      <td>-1</td>\n",
       "      <td>ساء جدا اسعار رسوم توصيل أمات واقع ب صل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>قعد عشرين سنة يدور على سائق بس اما عن توصيل ال...</td>\n",
       "      <td>0</td>\n",
       "      <td>قعد عشر سنة دار ساياق بس اما توصيل الاشياء جيد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>احلئ تطبيق</td>\n",
       "      <td>1</td>\n",
       "      <td>حلى تطبيق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>رائع واو مدهش</td>\n",
       "      <td>1</td>\n",
       "      <td>راياع واو مدهش</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>مکو بس البحرین وعمان وغیرهه بس العراق مکو یعنی...</td>\n",
       "      <td>-1</td>\n",
       "      <td>مکو بس البحرین عمان وغیرهه بس عراق مکو یعنی نج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>تطبيق جميل يستاهل الخمس نجوم👍👍👍</td>\n",
       "      <td>1</td>\n",
       "      <td>تطبيق جميل يستاهل خمس نجوم thumbsup thumbsup t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>هلا طلبات</td>\n",
       "      <td>1</td>\n",
       "      <td>هلا طلبة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>الاسمر عمار الريق مصر</td>\n",
       "      <td>1</td>\n",
       "      <td>اسمر عمار ريق مصر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ممتاز ومصدقة ودقه وسرعة في التوصيل الرجاء وضع ...</td>\n",
       "      <td>1</td>\n",
       "      <td>ممتاز مصدق دق سرع توصيل رجاء وضع أقام وجب او ط...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>هالبرنامج منقذ</td>\n",
       "      <td>1</td>\n",
       "      <td>هالبرنامج منقذ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>مرة سريع جاني الطلب حار انصح فيه بصراحة</td>\n",
       "      <td>1</td>\n",
       "      <td>مرة سريع جان طلب حار انصاح صراح</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>يو ار يو</td>\n",
       "      <td>1</td>\n",
       "      <td>يو ار يو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ما يوصل لأي مكان</td>\n",
       "      <td>-1</td>\n",
       "      <td>NOT_وصل NOT_مكان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>لو سمحت انا سالت قبل كده إذا كان في توصيل لمنط...</td>\n",
       "      <td>-1</td>\n",
       "      <td>لو سمح انا سالت قبل دهي اذا توصيل منطق بشتىل ن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>افضل تطبيق علی مر تاريخ</td>\n",
       "      <td>1</td>\n",
       "      <td>فضل تطبيق علی مر تاريخ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>طلبت طلبيه لي ساعه ويوم اتصلت عليهم قالو طلبكم...</td>\n",
       "      <td>-1</td>\n",
       "      <td>طلب طلب لي ساعى يوم اتصل على قال طلب اللغى حيو...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   review_description  rating  \\\n",
       "0   شركه زباله و سواقين بتبرشم و مفيش حتي رقم للشك...      -1   \n",
       "1   خدمة الدفع عن طريق الكي نت توقفت عندي اصبح فقط...       1   \n",
       "2   تطبيق غبي و جاري حذفه ، عاملين اكواد خصم و لما...      -1   \n",
       "3   فعلا تطبيق ممتاز بس لو فى امكانية يتيح لمستخدم...       1   \n",
       "4   سيء جدا ، اسعار رسوم التوصيل لا تمت للواقع ب ص...      -1   \n",
       "5   قعد عشرين سنة يدور على سائق بس اما عن توصيل ال...       0   \n",
       "6                                          احلئ تطبيق       1   \n",
       "7                                       رائع واو مدهش       1   \n",
       "8   مکو بس البحرین وعمان وغیرهه بس العراق مکو یعنی...      -1   \n",
       "9                     تطبيق جميل يستاهل الخمس نجوم👍👍👍       1   \n",
       "10                                          هلا طلبات       1   \n",
       "11                              الاسمر عمار الريق مصر       1   \n",
       "12  ممتاز ومصدقة ودقه وسرعة في التوصيل الرجاء وضع ...       1   \n",
       "13                                     هالبرنامج منقذ       1   \n",
       "14            مرة سريع جاني الطلب حار انصح فيه بصراحة       1   \n",
       "15                                           يو ار يو       1   \n",
       "16                                   ما يوصل لأي مكان      -1   \n",
       "17  لو سمحت انا سالت قبل كده إذا كان في توصيل لمنط...      -1   \n",
       "18                            افضل تطبيق علی مر تاريخ       1   \n",
       "19  طلبت طلبيه لي ساعه ويوم اتصلت عليهم قالو طلبكم...      -1   \n",
       "\n",
       "                                         final_tokens  \n",
       "0   شرك زبال سواق بتبرشم مفيش حت رقم للشكاوي سواق ...  \n",
       "1        خدم دفع طريق كي نات توقف عند صبح فقط دفع نقد  \n",
       "2   تطبيق غب جار حذف عامل اكواد خصم NOT_استخدم اكت...  \n",
       "3   علا تطبيق ممتاز بس لو فى امكانية أتاح مستخدم ت...  \n",
       "4             ساء جدا اسعار رسوم توصيل أمات واقع ب صل  \n",
       "5   قعد عشر سنة دار ساياق بس اما توصيل الاشياء جيد...  \n",
       "6                                           حلى تطبيق  \n",
       "7                                      راياع واو مدهش  \n",
       "8   مکو بس البحرین عمان وغیرهه بس عراق مکو یعنی نج...  \n",
       "9   تطبيق جميل يستاهل خمس نجوم thumbsup thumbsup t...  \n",
       "10                                           هلا طلبة  \n",
       "11                                  اسمر عمار ريق مصر  \n",
       "12  ممتاز مصدق دق سرع توصيل رجاء وضع أقام وجب او ط...  \n",
       "13                                     هالبرنامج منقذ  \n",
       "14                    مرة سريع جان طلب حار انصاح صراح  \n",
       "15                                           يو ار يو  \n",
       "16                                   NOT_وصل NOT_مكان  \n",
       "17  لو سمح انا سالت قبل دهي اذا توصيل منطق بشتىل ن...  \n",
       "18                             فضل تطبيق علی مر تاريخ  \n",
       "19  طلب طلب لي ساعى يوم اتصل على قال طلب اللغى حيو...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying all the Processing+Visualization\n",
    "df_train['final_tokens'] = df_train['review_description'].apply(\n",
    "    lambda x: text_processing_pipeline(x, stemmer, lemmatizer, tokenizer, stop_words)\n",
    ")\n",
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7145815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Empty Rows\n",
    "df_train = df_train[df_train['final_tokens'].apply(lambda x: len(x) > 0)]\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_train.loc[:, 'rating'] = df_train['rating'][df_train['final_tokens'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad15bb",
   "metadata": {},
   "source": [
    "### Vocabulary Preparation/Sequencing/Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e7b1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train['final_tokens']\n",
    "y = df_train[\"rating\"].astype(int) + 1\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "tokenizerr = Tokenizer(oov_token=\"<UNK>\")\n",
    "tokenizerr.fit_on_texts(X)\n",
    "total_words = len(tokenizerr.word_index) + 1\n",
    "\n",
    "sequences = tokenizerr.texts_to_sequences(X)\n",
    "max_len = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4eda3a",
   "metadata": {},
   "source": [
    "### Data Splitting Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972b4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    padded_sequences, y, test_size=0.2, random_state=333, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427531c",
   "metadata": {},
   "source": [
    "### Handling Class Imbalances/Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a319e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 leeh 1.5k row w 1 leeh 20k row .. f b handle da enii a-adjust el weights :D '''\n",
    "#class_weights = dict(zip(y_train.value_counts().index, len(y_train) / (y_train.value_counts() * len(y_train.unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2ff2c",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1abbbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(\n",
    "        input_dim=len(tokenizerr.word_index) + 1,\n",
    "        output_dim=300,\n",
    "        input_length=X_train.shape[1],\n",
    "    )\n",
    ")\n",
    "model.add(LSTM(32, activation=\"tanh\", dropout=0.3))\n",
    "model.add(Dense(num_classes, activation=\"softmax\", kernel_regularizer=l2(0.1)))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"./LSTM-emb.hdf5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132c597",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79d429a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "799/799 [==============================] - 351s 436ms/step - loss: 0.6723 - accuracy: 0.8011 - val_loss: 0.5244 - val_accuracy: 0.8365\n",
      "Epoch 2/4\n",
      "799/799 [==============================] - 349s 437ms/step - loss: 0.4309 - accuracy: 0.8722 - val_loss: 0.5205 - val_accuracy: 0.8317\n",
      "Epoch 3/4\n",
      "799/799 [==============================] - 350s 438ms/step - loss: 0.3535 - accuracy: 0.9012 - val_loss: 0.5388 - val_accuracy: 0.8221\n",
      "Epoch 4/4\n",
      "799/799 [==============================] - 354s 443ms/step - loss: 0.3109 - accuracy: 0.9133 - val_loss: 0.5517 - val_accuracy: 0.8232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e67fb4ee50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=4,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef5040",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1c64184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 19s 95ms/step - loss: 0.5244 - accuracy: 0.8365\n",
      "Validation Loss: 0.5244214534759521, Validation Accuracy: 0.8365429639816284\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"./LSTM-emb.hdf5\")\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5cfa09",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c3e2744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>اهنئكم على خدمه العملاء في المحادثه المباشره م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ممتاز جدا ولكن اتمنى ان تكون هناك بعض المسابقا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>كل محملته يقول تم ايقاف حطيت2 عشان تسوون الخطاء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>شغل طيب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>بعد ماجربت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>يستهل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>خدمة سيئة بكل المعايير</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>لؤي٠٣٣٢لؤ٣٤٣س</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>تطبيق غير صادق ف خصم الكوبونات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>تأخير + الموظفين غير مؤهلة .للأسف انا استخدم ط...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                 review_description\n",
       "0       1  اهنئكم على خدمه العملاء في المحادثه المباشره م...\n",
       "1       2  ممتاز جدا ولكن اتمنى ان تكون هناك بعض المسابقا...\n",
       "2       3    كل محملته يقول تم ايقاف حطيت2 عشان تسوون الخطاء\n",
       "3       4                                            شغل طيب\n",
       "4       5                                         بعد ماجربت\n",
       "..    ...                                                ...\n",
       "995   996                                              يستهل\n",
       "996   997                             خدمة سيئة بكل المعايير\n",
       "997   998                                      لؤي٠٣٣٢لؤ٣٤٣س\n",
       "998   999                     تطبيق غير صادق ف خصم الكوبونات\n",
       "999  1000  تأخير + الموظفين غير مؤهلة .للأسف انا استخدم ط...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading/Loading Test Data\n",
    "file_path = \"test _no_label.csv\" # Path on Kaggle: /kaggle/input/arabic-sentiment-analysis-nlp/test _no_label.csv\n",
    "df_test = pd.read_csv(file_path)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bba97813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32037\n",
      "32038\n",
      "32039\n",
      "32040\n",
      "32041\n",
      "32042\n",
      "32043\n",
      "32044\n",
      "32045\n",
      "32046\n",
      "32047\n",
      "32048\n",
      "32049\n",
      "32050\n",
      "32051\n",
      "32052\n",
      "32053\n",
      "32054\n",
      "32055\n",
      "32056\n",
      "32057\n",
      "32058\n",
      "32059\n",
      "32060\n",
      "32061\n",
      "32062\n",
      "32063\n",
      "32064\n",
      "32065\n",
      "32066\n",
      "32067\n",
      "32068\n",
      "32069\n",
      "32070\n",
      "32071\n",
      "32072\n",
      "32073\n",
      "32074\n",
      "32075\n",
      "32076\n",
      "32077\n",
      "32078\n",
      "32079\n",
      "32080\n",
      "32081\n",
      "32082\n",
      "32083\n",
      "32084\n",
      "32085\n",
      "32086\n",
      "32087\n",
      "32088\n",
      "32089\n",
      "32090\n",
      "32091\n",
      "32092\n",
      "32093\n",
      "32094\n",
      "32095\n",
      "32096\n",
      "32097\n",
      "32098\n",
      "32099\n",
      "32100\n",
      "32101\n",
      "32102\n",
      "32103\n",
      "32104\n",
      "32105\n",
      "32106\n",
      "32107\n",
      "32108\n",
      "32109\n",
      "32110\n",
      "32111\n",
      "32112\n",
      "32113\n",
      "32114\n",
      "32115\n",
      "32116\n",
      "32117\n",
      "32118\n",
      "32119\n",
      "32120\n",
      "32121\n",
      "32122\n",
      "32123\n",
      "32124\n",
      "32125\n",
      "32126\n",
      "32127\n",
      "32128\n",
      "32129\n",
      "32130\n",
      "32131\n",
      "32132\n",
      "32133\n",
      "32134\n",
      "32135\n",
      "32136\n",
      "32137\n",
      "32138\n",
      "32139\n",
      "32140\n",
      "32141\n",
      "32142\n",
      "32143\n",
      "32144\n",
      "32145\n",
      "32146\n",
      "32147\n",
      "32148\n",
      "32149\n",
      "32150\n",
      "32151\n",
      "32152\n",
      "32153\n",
      "32154\n",
      "32155\n",
      "32156\n",
      "32157\n",
      "32158\n",
      "32159\n",
      "32160\n",
      "32161\n",
      "32162\n",
      "32163\n",
      "32164\n",
      "32165\n",
      "32166\n",
      "32167\n",
      "32168\n",
      "32169\n",
      "32170\n",
      "32171\n",
      "32172\n",
      "32173\n",
      "32174\n",
      "32175\n",
      "32176\n",
      "32177\n",
      "32178\n",
      "32179\n",
      "32180\n",
      "32181\n",
      "32182\n",
      "32183\n",
      "32184\n",
      "32185\n",
      "32186\n",
      "32187\n",
      "32188\n",
      "32189\n",
      "32190\n",
      "32191\n",
      "32192\n",
      "32193\n",
      "32194\n",
      "32195\n",
      "32196\n",
      "32197\n",
      "32198\n",
      "32199\n",
      "32200\n",
      "32201\n",
      "32202\n",
      "32203\n",
      "32204\n",
      "32205\n",
      "32206\n",
      "32207\n",
      "32208\n",
      "32209\n",
      "32210\n",
      "32211\n",
      "32212\n",
      "32213\n",
      "32214\n",
      "32215\n",
      "32216\n",
      "32217\n",
      "32218\n",
      "32219\n",
      "32220\n",
      "32221\n",
      "32222\n",
      "32223\n",
      "32224\n",
      "32225\n",
      "32226\n",
      "32227\n",
      "32228\n",
      "32229\n",
      "32230\n",
      "32231\n",
      "32232\n",
      "32233\n",
      "32234\n",
      "32235\n",
      "32236\n",
      "32237\n",
      "32238\n",
      "32239\n",
      "32240\n",
      "32241\n",
      "32242\n",
      "32243\n",
      "32244\n",
      "32245\n",
      "32246\n",
      "32247\n",
      "32248\n",
      "32249\n",
      "32250\n",
      "32251\n",
      "32252\n",
      "32253\n",
      "32254\n",
      "32255\n",
      "32256\n",
      "32257\n",
      "32258\n",
      "32259\n",
      "32260\n",
      "32261\n",
      "32262\n",
      "32263\n",
      "32264\n",
      "32265\n",
      "32266\n",
      "32267\n",
      "32268\n",
      "32269\n",
      "32270\n",
      "32271\n",
      "32272\n",
      "32273\n",
      "32274\n",
      "32275\n",
      "32276\n",
      "32277\n",
      "32278\n",
      "32279\n",
      "32280\n",
      "32281\n",
      "32282\n",
      "32283\n",
      "32284\n",
      "32285\n",
      "32286\n",
      "32287\n",
      "32288\n",
      "32289\n",
      "32290\n",
      "32291\n",
      "32292\n",
      "32293\n",
      "32294\n",
      "32295\n",
      "32296\n",
      "32297\n",
      "32298\n",
      "32299\n",
      "32300\n",
      "32301\n",
      "32302\n",
      "32303\n",
      "32304\n",
      "32305\n",
      "32306\n",
      "32307\n",
      "32308\n",
      "32309\n",
      "32310\n",
      "32311\n",
      "32312\n",
      "32313\n",
      "32314\n",
      "32315\n",
      "32316\n",
      "32317\n",
      "32318\n",
      "32319\n",
      "32320\n",
      "32321\n",
      "32322\n",
      "32323\n",
      "32324\n",
      "32325\n",
      "32326\n",
      "32327\n",
      "32328\n",
      "32329\n",
      "32330\n",
      "32331\n",
      "32332\n",
      "32333\n",
      "32334\n",
      "32335\n",
      "32336\n",
      "32337\n",
      "32338\n",
      "32339\n",
      "32340\n",
      "32341\n",
      "32342\n",
      "32343\n",
      "32344\n",
      "32345\n",
      "32346\n",
      "32347\n",
      "32348\n",
      "32349\n",
      "32350\n",
      "32351\n",
      "32352\n",
      "32353\n",
      "32354\n",
      "32355\n",
      "32356\n",
      "32357\n",
      "32358\n",
      "32359\n",
      "32360\n",
      "32361\n",
      "32362\n",
      "32363\n",
      "32364\n",
      "32365\n",
      "32366\n",
      "32367\n",
      "32368\n",
      "32369\n",
      "32370\n",
      "32371\n",
      "32372\n",
      "32373\n",
      "32374\n",
      "32375\n",
      "32376\n",
      "32377\n",
      "32378\n",
      "32379\n",
      "32380\n",
      "32381\n",
      "32382\n",
      "32383\n",
      "32384\n",
      "32385\n",
      "32386\n",
      "32387\n",
      "32388\n",
      "32389\n",
      "32390\n",
      "32391\n",
      "32392\n",
      "32393\n",
      "32394\n",
      "32395\n",
      "32396\n",
      "32397\n",
      "32398\n",
      "32399\n",
      "32400\n",
      "32401\n",
      "32402\n",
      "32403\n",
      "32404\n",
      "32405\n",
      "32406\n",
      "32407\n",
      "32408\n",
      "32409\n",
      "32410\n",
      "32411\n",
      "32412\n",
      "32413\n",
      "32414\n",
      "32415\n",
      "32416\n",
      "32417\n",
      "32418\n",
      "32419\n",
      "32420\n",
      "32421\n",
      "32422\n",
      "32423\n",
      "32424\n",
      "32425\n",
      "32426\n",
      "32427\n",
      "32428\n",
      "32429\n",
      "32430\n",
      "32431\n",
      "32432\n",
      "32433\n",
      "32434\n",
      "32435\n",
      "32436\n",
      "32437\n",
      "32438\n",
      "32439\n",
      "32440\n",
      "32441\n",
      "32442\n",
      "32443\n",
      "32444\n",
      "32445\n",
      "32446\n",
      "32447\n",
      "32448\n",
      "32449\n",
      "32450\n",
      "32451\n",
      "32452\n",
      "32453\n",
      "32454\n",
      "32455\n",
      "32456\n",
      "32457\n",
      "32458\n",
      "32459\n",
      "32460\n",
      "32461\n",
      "32462\n",
      "32463\n",
      "32464\n",
      "32465\n",
      "32466\n",
      "32467\n",
      "32468\n",
      "32469\n",
      "32470\n",
      "32471\n",
      "32472\n",
      "32473\n",
      "32474\n",
      "32475\n",
      "32476\n",
      "32477\n",
      "32478\n",
      "32479\n",
      "32480\n",
      "32481\n",
      "32482\n",
      "32483\n",
      "32484\n",
      "32485\n",
      "32486\n",
      "32487\n",
      "32488\n",
      "32489\n",
      "32490\n",
      "32491\n",
      "32492\n",
      "32493\n",
      "32494\n",
      "32495\n",
      "32496\n",
      "32497\n",
      "32498\n",
      "32499\n",
      "32500\n",
      "32501\n",
      "32502\n",
      "32503\n",
      "32504\n",
      "32505\n",
      "32506\n",
      "32507\n",
      "32508\n",
      "32509\n",
      "32510\n",
      "32511\n",
      "32512\n",
      "32513\n",
      "32514\n",
      "32515\n",
      "32516\n",
      "32517\n",
      "32518\n",
      "32519\n",
      "32520\n",
      "32521\n",
      "32522\n",
      "32523\n",
      "32524\n",
      "32525\n",
      "32526\n",
      "32527\n",
      "32528\n",
      "32529\n",
      "32530\n",
      "32531\n",
      "32532\n",
      "32533\n",
      "32534\n",
      "32535\n",
      "32536\n",
      "32537\n",
      "32538\n",
      "32539\n",
      "32540\n",
      "32541\n",
      "32542\n",
      "32543\n",
      "32544\n",
      "32545\n",
      "32546\n",
      "32547\n",
      "32548\n",
      "32549\n",
      "32550\n",
      "32551\n",
      "32552\n",
      "32553\n",
      "32554\n",
      "32555\n",
      "32556\n",
      "32557\n",
      "32558\n",
      "32559\n",
      "32560\n",
      "32561\n",
      "32562\n",
      "32563\n",
      "32564\n",
      "32565\n",
      "32566\n",
      "32567\n",
      "32568\n",
      "32569\n",
      "32570\n",
      "32571\n",
      "32572\n",
      "32573\n",
      "32574\n",
      "32575\n",
      "32576\n",
      "32577\n",
      "32578\n",
      "32579\n",
      "32580\n",
      "32581\n",
      "32582\n",
      "32583\n",
      "32584\n",
      "32585\n",
      "32586\n",
      "32587\n",
      "32588\n",
      "32589\n",
      "32590\n",
      "32591\n",
      "32592\n",
      "32593\n",
      "32594\n",
      "32595\n",
      "32596\n",
      "32597\n",
      "32598\n",
      "32599\n",
      "32600\n",
      "32601\n",
      "32602\n",
      "32603\n",
      "32604\n",
      "32605\n",
      "32606\n",
      "32607\n",
      "32608\n",
      "32609\n",
      "32610\n",
      "32611\n",
      "32612\n",
      "32613\n",
      "32614\n",
      "32615\n",
      "32616\n",
      "32617\n",
      "32618\n",
      "32619\n",
      "32620\n",
      "32621\n",
      "32622\n",
      "32623\n",
      "32624\n",
      "32625\n",
      "32626\n",
      "32627\n",
      "32628\n",
      "32629\n",
      "32630\n",
      "32631\n",
      "32632\n",
      "32633\n",
      "32634\n",
      "32635\n",
      "32636\n",
      "32637\n",
      "32638\n",
      "32639\n",
      "32640\n",
      "32641\n",
      "32642\n",
      "32643\n",
      "32644\n",
      "32645\n",
      "32646\n",
      "32647\n",
      "32648\n",
      "32649\n",
      "32650\n",
      "32651\n",
      "32652\n",
      "32653\n",
      "32654\n",
      "32655\n",
      "32656\n",
      "32657\n",
      "32658\n",
      "32659\n",
      "32660\n",
      "32661\n",
      "32662\n",
      "32663\n",
      "32664\n",
      "32665\n",
      "32666\n",
      "32667\n",
      "32668\n",
      "32669\n",
      "32670\n",
      "32671\n",
      "32672\n",
      "32673\n",
      "32674\n",
      "32675\n",
      "32676\n",
      "32677\n",
      "32678\n",
      "32679\n",
      "32680\n",
      "32681\n",
      "32682\n",
      "32683\n",
      "32684\n",
      "32685\n",
      "32686\n",
      "32687\n",
      "32688\n",
      "32689\n",
      "32690\n",
      "32691\n",
      "32692\n",
      "32693\n",
      "32694\n",
      "32695\n",
      "32696\n",
      "32697\n",
      "32698\n",
      "32699\n",
      "32700\n",
      "32701\n",
      "32702\n",
      "32703\n",
      "32704\n",
      "32705\n",
      "32706\n",
      "32707\n",
      "32708\n",
      "32709\n",
      "32710\n",
      "32711\n",
      "32712\n",
      "32713\n",
      "32714\n",
      "32715\n",
      "32716\n",
      "32717\n",
      "32718\n",
      "32719\n",
      "32720\n",
      "32721\n",
      "32722\n",
      "32723\n",
      "32724\n",
      "32725\n",
      "32726\n",
      "32727\n",
      "32728\n",
      "32729\n",
      "32730\n",
      "32731\n",
      "32732\n",
      "32733\n",
      "32734\n",
      "32735\n",
      "32736\n",
      "32737\n",
      "32738\n",
      "32739\n",
      "32740\n",
      "32741\n",
      "32742\n",
      "32743\n",
      "32744\n",
      "32745\n",
      "32746\n",
      "32747\n",
      "32748\n",
      "32749\n",
      "32750\n",
      "32751\n",
      "32752\n",
      "32753\n",
      "32754\n",
      "32755\n",
      "32756\n",
      "32757\n",
      "32758\n",
      "32759\n",
      "32760\n",
      "32761\n",
      "32762\n",
      "32763\n",
      "32764\n",
      "32765\n",
      "32766\n",
      "32767\n",
      "32768\n",
      "32769\n",
      "32770\n",
      "32771\n",
      "32772\n",
      "32773\n",
      "32774\n",
      "32775\n",
      "32776\n",
      "32777\n",
      "32778\n",
      "32779\n",
      "32780\n",
      "32781\n",
      "32782\n",
      "32783\n",
      "32784\n",
      "32785\n",
      "32786\n",
      "32787\n",
      "32788\n",
      "32789\n",
      "32790\n",
      "32791\n",
      "32792\n",
      "32793\n",
      "32794\n",
      "32795\n",
      "32796\n",
      "32797\n",
      "32798\n",
      "32799\n",
      "32800\n",
      "32801\n",
      "32802\n",
      "32803\n",
      "32804\n",
      "32805\n",
      "32806\n",
      "32807\n",
      "32808\n",
      "32809\n",
      "32810\n",
      "32811\n",
      "32812\n",
      "32813\n",
      "32814\n",
      "32815\n",
      "32816\n",
      "32817\n",
      "32818\n",
      "32819\n",
      "32820\n",
      "32821\n",
      "32822\n",
      "32823\n",
      "32824\n",
      "32825\n",
      "32826\n",
      "32827\n",
      "32828\n",
      "32829\n",
      "32830\n",
      "32831\n",
      "32832\n",
      "32833\n",
      "32834\n",
      "32835\n",
      "32836\n",
      "32837\n",
      "32838\n",
      "32839\n",
      "32840\n",
      "32841\n",
      "32842\n",
      "32843\n",
      "32844\n",
      "32845\n",
      "32846\n",
      "32847\n",
      "32848\n",
      "32849\n",
      "32850\n",
      "32851\n",
      "32852\n",
      "32853\n",
      "32854\n",
      "32855\n",
      "32856\n",
      "32857\n",
      "32858\n",
      "32859\n",
      "32860\n",
      "32861\n",
      "32862\n",
      "32863\n",
      "32864\n",
      "32865\n",
      "32866\n",
      "32867\n",
      "32868\n",
      "32869\n",
      "32870\n",
      "32871\n",
      "32872\n",
      "32873\n",
      "32874\n",
      "32875\n",
      "32876\n",
      "32877\n",
      "32878\n",
      "32879\n",
      "32880\n",
      "32881\n",
      "32882\n",
      "32883\n",
      "32884\n",
      "32885\n",
      "32886\n",
      "32887\n",
      "32888\n",
      "32889\n",
      "32890\n",
      "32891\n",
      "32892\n",
      "32893\n",
      "32894\n",
      "32895\n",
      "32896\n",
      "32897\n",
      "32898\n",
      "32899\n",
      "32900\n",
      "32901\n",
      "32902\n",
      "32903\n",
      "32904\n",
      "32905\n",
      "32906\n",
      "32907\n",
      "32908\n",
      "32909\n",
      "32910\n",
      "32911\n",
      "32912\n",
      "32913\n",
      "32914\n",
      "32915\n",
      "32916\n",
      "32917\n",
      "32918\n",
      "32919\n",
      "32920\n",
      "32921\n",
      "32922\n",
      "32923\n",
      "32924\n",
      "32925\n",
      "32926\n",
      "32927\n",
      "32928\n",
      "32929\n",
      "32930\n",
      "32931\n",
      "32932\n",
      "32933\n",
      "32934\n",
      "32935\n",
      "32936\n",
      "32937\n",
      "32938\n",
      "32939\n",
      "32940\n",
      "32941\n",
      "32942\n",
      "32943\n",
      "32944\n",
      "32945\n",
      "32946\n",
      "32947\n",
      "32948\n",
      "32949\n",
      "32950\n",
      "32951\n",
      "32952\n",
      "32953\n",
      "32954\n",
      "32955\n",
      "32956\n",
      "32957\n",
      "32958\n",
      "32959\n",
      "32960\n",
      "32961\n",
      "32962\n",
      "32963\n",
      "32964\n",
      "32965\n",
      "32966\n",
      "32967\n",
      "32968\n",
      "32969\n",
      "32970\n",
      "32971\n",
      "32972\n",
      "32973\n",
      "32974\n",
      "32975\n",
      "32976\n",
      "32977\n",
      "32978\n",
      "32979\n",
      "32980\n",
      "32981\n",
      "32982\n",
      "32983\n",
      "32984\n",
      "32985\n",
      "32986\n",
      "32987\n",
      "32988\n",
      "32989\n",
      "32990\n",
      "32991\n",
      "32992\n",
      "32993\n",
      "32994\n",
      "32995\n",
      "32996\n",
      "32997\n",
      "32998\n",
      "32999\n",
      "33000\n",
      "33001\n",
      "33002\n",
      "33003\n",
      "33004\n",
      "33005\n",
      "33006\n",
      "33007\n",
      "33008\n",
      "33009\n",
      "33010\n",
      "33011\n",
      "33012\n",
      "33013\n",
      "33014\n",
      "33015\n",
      "33016\n",
      "33017\n",
      "33018\n",
      "33019\n",
      "33020\n",
      "33021\n",
      "33022\n",
      "33023\n",
      "33024\n",
      "33025\n",
      "33026\n",
      "33027\n",
      "33028\n",
      "33029\n",
      "33030\n",
      "33031\n",
      "33032\n",
      "33033\n",
      "33034\n",
      "33035\n",
      "33036\n",
      "There are 3 empty rows..\n"
     ]
    }
   ],
   "source": [
    "# Same steps/processing should be applied on Test Data\n",
    "df_test['final_tokens'] = df_test['review_description'].apply(\n",
    "    lambda x: text_processing_pipeline(x, stemmer, lemmatizer, tokenizer, stop_words)\n",
    ")\n",
    "\n",
    "#empty_rows = df_test['final_tokens'].apply(lambda x: len(x) == 0)\n",
    "#df_test[empty_rows]\n",
    "print(\"There are 3 empty rows..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cfa2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding Test Data\n",
    "sequences_test = tokenizerr.texts_to_sequences(df_test['final_tokens'])\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6f6159e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "# Padding Test Data to the Model and Saving Predictions\n",
    "predictions = model.predict(padded_sequences_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1) - 1\n",
    "\n",
    "output_df = pd.DataFrame({\"ID\": df_test[\"ID\"], \"rating\": predicted_labels})\n",
    "\n",
    "output_df.to_csv(\"test_results_LSTM_emb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
